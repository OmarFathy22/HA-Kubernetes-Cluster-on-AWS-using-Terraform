 # HA Kubernetes Cluster on AWS (Terraform + Ansible)

[![Deploy HA Kubernetes Cluster](https://github.com/OmarFathy22/HA-Kubernetes-Cluster-on-AWS-using-Terraform/actions/workflows/deploy-k8s-cluster.yml/badge.svg?branch=platform)](https://github.com/OmarFathy22/HA-Kubernetes-Cluster-on-AWS-using-Terraform/actions/workflows/deploy-k8s-cluster.yml)
[![Destroy Cluster](https://github.com/OmarFathy22/HA-Kubernetes-Cluster-on-AWS-using-Terraform/actions/workflows/destroy-k8s-cluster.yml/badge.svg?branch=platform)](https://github.com/OmarFathy22/HA-Kubernetes-Cluster-on-AWS-using-Terraform/actions/workflows/destroy-k8s-cluster.yml)

Production-ready, highly available Kubernetes cluster on AWS using only Terraform + Ansible (no EKS, no managed services).

---

## ğŸ‰ What's New: Ansible Integration

**v2.0 - Complete Refactor from Bash Scripts to Ansible**

| Before (v1.0) | After (v2.0) |
|---------------|--------------|
| âŒ Bash scripts in EC2 user_data | âœ… Ansible playbooks & roles |
| âŒ Can't re-run without recreating | âœ… Idempotent - run anytime |
| âŒ Hard to debug and maintain | âœ… Clear, readable YAML |
| âŒ No upgrade path | âœ… In-place Kubernetes upgrades |
| âŒ Manual IP management | âœ… Auto-generated inventory |

**Key Benefits:**
- ğŸ”„ **Idempotent**: Safe to run multiple times
- ğŸ¯ **Maintainable**: Easy-to-read YAML instead of bash
- ğŸš€ **Upgradeable**: Update Kubernetes without destroying cluster
- ğŸ”§ **Testable**: Run specific tasks with tags
- ğŸ“Š **Professional**: Industry-standard automation

---

## ğŸ—ï¸ Architecture

```
                    Internet Gateway
                           |
              Network Load Balancer (API :6443)
                           |
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                  â”‚                  â”‚
    Master-01          Master-02         Master-03
    (Leader)          (Follower)        (Follower)
        â”‚                  â”‚                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           |
                    etcd HA Cluster
                           |
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                     â”‚
            Worker-01             Worker-02
                
                S3 Bucket (Bootstrap Coordination)
```

**Components:**
- 3 Master Nodes (HA control plane)
- 2 Worker Nodes (workloads)
- Network Load Balancer (single API endpoint)
- S3 Bucket (join token coordination)
- Calico CNI (pod networking)

---

## ğŸ“‹ Prerequisites

```bash
# Required tools
terraform --version  # >= 1.7
ansible --version    # >= 2.15
aws --version        # >= 2.x
jq --version         # for inventory generation

# AWS
- AWS Account with IAM permissions
- EC2 key pair for SSH access
- AWS CLI configured (aws configure)
```

**Install tools:**
```bash
# Ubuntu/Debian
sudo apt install -y terraform ansible awscli jq

# macOS
brew install terraform ansible awscli jq
```

---

## ğŸš€ Quick Start (3 Simple Steps)

### Step 1: Deploy Infrastructure with Terraform

```bash
cd terraform
terraform init
terraform apply -auto-approve

# Wait ~5 minutes for EC2 instances
```

### Step 2: Generate Ansible Inventory

```bash
cd ../ansible
chmod +x generate-inventory.sh
./generate-inventory.sh

# Edit SSH key path in generated inventory
nano inventory/hosts.ini
# Update: ansible_ssh_private_key_file=~/.ssh/your-key.pem
```

### Step 3: Deploy Kubernetes with Ansible

```bash
ansible-playbook playbooks/site.yml

# Total time: ~40 minutes
# âœ“ Prepare nodes (15-20 min)
# âœ“ Initialize first master (5-10 min)
# âœ“ Join additional masters (5 min)
# âœ“ Join workers (5 min)
```

### Access Your Cluster

```bash
# Get master IP
MASTER_IP=$(grep master01 inventory/hosts.ini | awk '{print $2}' | cut -d'=' -f2)

# Copy kubeconfig
scp -i ~/.ssh/your-key.pem ubuntu@${MASTER_IP}:/root/.kube/config ~/.kube/config

# Verify
kubectl get nodes
```

**Expected output:**
```
NAME       STATUS   ROLES           AGE   VERSION
master01   Ready    control-plane   10m   v1.33.0
master02   Ready    control-plane   8m    v1.33.0
master03   Ready    control-plane   6m    v1.33.0
worker01   Ready    worker          4m    v1.33.0
worker02   Ready    worker          4m    v1.33.0
```

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ terraform/                 # Infrastructure (AWS resources)
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ variables.tf
â”‚   â”œâ”€â”€ outputs.tf            # Used by Ansible
â”‚   â””â”€â”€ modules/
â”‚       â”œâ”€â”€ vpc/
â”‚       â”œâ”€â”€ security_groups/
â”‚       â”œâ”€â”€ load_balancer/
â”‚       â”œâ”€â”€ s3/
â”‚       â””â”€â”€ ec2/
â”‚
â””â”€â”€ ansible/                   # Configuration (Kubernetes setup)
    â”œâ”€â”€ ansible.cfg
    â”œâ”€â”€ generate-inventory.sh  # Auto-creates inventory from Terraform
    â”œâ”€â”€ inventory/
    â”‚   â”œâ”€â”€ hosts.ini         # Generated automatically
    â”‚   â””â”€â”€ group_vars/
    â”‚       â”œâ”€â”€ all.yml       # Global variables (K8s version, LB DNS)
    â”‚       â”œâ”€â”€ masters.yml
    â”‚       â””â”€â”€ workers.yml
    â”œâ”€â”€ playbooks/
    â”‚   â””â”€â”€ site.yml          # Main playbook
    â””â”€â”€ roles/
        â”œâ”€â”€ common/           # Setup all nodes
        â”œâ”€â”€ kubernetes-master/ # Setup masters
        â”œâ”€â”€ kubernetes-worker/ # Setup workers
        
```

---

## ğŸ”§ Common Operations

### Add More Workers

```bash
# Update Terraform
cd terraform
terraform apply -var="worker_count=4"

# Regenerate inventory
cd ../ansible
./generate-inventory.sh

# Deploy new workers only
ansible-playbook playbooks/site.yml --limit worker03,worker04 --tags prepare,workers
```

### Run Specific Tasks

```bash
# Only prepare nodes
ansible-playbook playbooks/site.yml --tags prepare

# Only setup masters
ansible-playbook playbooks/site.yml --tags masters

# Only join workers
ansible-playbook playbooks/site.yml --tags workers
```

### Re-run Deployment (Safe!)

```bash
# Ansible is idempotent - safe to run multiple times
ansible-playbook playbooks/site.yml

# It will:
# âœ“ Skip already completed tasks
# âœ“ Fix any configuration drift
# âœ“ Complete any failed tasks
```

---

## ğŸ› Troubleshooting

### Test SSH Connectivity

```bash
# Test all nodes
ansible all -m ping

# If it fails, check:
chmod 400 ~/.ssh/your-key.pem
ssh -i ~/.ssh/your-key.pem ubuntu@<master-ip>
```

### Debug Ansible Execution

```bash
# Verbose output
ansible-playbook playbooks/site.yml -vvv

# Run on specific node
ansible-playbook playbooks/site.yml --limit master02

# Start from specific task
ansible-playbook playbooks/site.yml --start-at-task="Install containerd"
```

### Check Node Status

```bash
# SSH to node
ssh -i ~/.ssh/your-key.pem ubuntu@<node-ip>

# Check services
sudo systemctl status kubelet
sudo systemctl status containerd

# Check logs
sudo journalctl -u kubelet -f
```

---

## ğŸ§¹ Cleanup

```bash
cd terraform
terraform destroy -auto-approve
```

---

## ğŸ“Š Specifications

**Kubernetes**: v1.33 (latest stable)  
**Container Runtime**: containerd with systemd cgroups  
**CNI Plugin**: Calico v3.27.3  
**Instance Type**: t3.medium (2 vCPU, 4GB RAM)  
**OS**: Ubuntu 22.04 LTS  
**Storage**: 20GB per instance  

---

## ğŸ¯ Why Ansible Over Bash Scripts?

### Bash Scripts (v1.0)
```bash
#!/bin/bash
apt-get update || true
kubeadm init ... > /tmp/out 2>&1 || (cat /tmp/out; exit 1)
# If fails at line 100, destroy and start over
```

### Ansible (v2.0)
```yaml
- name: Update packages
  apt:
    update_cache: yes
  retries: 3

- name: Initialize cluster
  command: kubeadm init ...
  when: not already_initialized
  register: result
```

**Result:** Readable, maintainable, and re-runnable automation.

---


## ğŸ“ License

MIT License - Feel free to use and modify

---

## ğŸ¤ Contributing

Contributions welcome! Please open an issue or submit a PR.

---

**Built with â¤ï¸ using Terraform, Ansible, and Kubernetes**
